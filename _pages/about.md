---
permalink: /
title: "Hi, I'm Donghyeon Joo, researching Support for Sparse LLMs."
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

This includes:
- Deriving sparsity in LLM weights and KV cache (mainly unstructured sparsity these days)
- GPU kernel support for sparse LLMs
- Architecture support for sparse LLMs

I am a second year Ph.D. Student in University of Maryland, College Park, advised by Professor Bahar Asgari in Computer Architecture and Systems Lab (CASL).

## Publications

*(I am a huge Star Wars fan, on a personal mission to name my papers with memorable planet names from the prequel/original trilogy)*

### Conference
**CORUSCANT: Co-Designing GPU Kernel and Sparse Tensor Core to Advocate Unstructured Sparsity in Efficient LLM Inference**  
Donghyeon Joo, Helya Hosseini, Ramyad Hadidi, Bahar Asgari  
*MICRO 2025 (To appear)*  
*Where Palpatine WAS the senate*

**PIPIRIMA: Predicting Patterns in Sparsity to Accelerate Matrix Algebra**  
Ubaid Bakhtiar, Donghyeon Joo, Bahar Asgari  
*DAC 2025*

### Journal
**SEGIN: Synergistically Enabling Fine-Grained Multi-Tenant and Resource Optimized SpMV**  
Helya Hosseini, Ubaid Bakhtiar, Donghyeon Joo, Bahar Asgari  
*CAL 2025*

### Preprint
**MUSTAFAR: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference**  
Donghyeon Joo, Helya Hosseini, Ramyad Hadidi, Bahar Asgari  
*Where Obi-wan had the high ground*

**ENDOR: Hardware-Friendly Sparse Format for Offloaded LLM Inference**  
Donghyeon Joo, Ramyad Hadidi, Soheil Feizi, Bahar Asgari  
*Where Ewoks were really cute*

## Education
**University of Maryland, College Park** (2023/Aug – Present)  
Ph.D. Student in Computer Science

**Korea University** (2017/Mar – 2023/Feb)  
Bachelor of Engineering in Electrical Engineering

## Work Experience
**SK Hynix America, San Jose, USA** (2024/Jun – Aug)  
AI Memory System Research Intern (Director: Dr. Jongryool Kim)
